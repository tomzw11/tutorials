{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620b1bb9-d188-4916-8a88-392b301e78dd",
   "metadata": {},
   "source": [
    "## mindspore.ops.conv3d(input, weight, bias=None, stride=1, pad_mode='valid', padding=0, dilation=1, groups=1) -〉 Tensor\n",
    "对输入Tensor计算二维卷积。\n",
    "\n",
    "- 输入：\n",
    "    * input：mindspore的tensor，输入。\n",
    "    * weight：mindspore的tensor，卷积核。\n",
    "    * bias：mindspore的tensor，偏置。\n",
    "    * stride：mindspore的tensor，步长。\n",
    "    * pad_mode：str，枚举值为\"same\"、\"valid\"或\"pad\"，填充模式。\n",
    "    * padding：int、tuple[int]、list[int]，填充的数量。\n",
    "    * dilation：int、tuple[int]，卷积核元素之间的间距。\n",
    "    * groups：int, 将input拆分为几组。\n",
    "\n",
    "- 返回：mindspore的tensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e9673-ea88-4efc-86bf-61455d0bcd74",
   "metadata": {},
   "source": [
    "1、参数比较：\n",
    "| mindspore   | torch       |\n",
    "| :----:      | :----:      |\n",
    "| input       | input       |\n",
    "| weight      | weight      |\n",
    "| bias        | bias        |\n",
    "| stride      | stride      |\n",
    "| pad_mode    | -           |\n",
    "| padding     | padding     |\n",
    "| dilation    | dilation    |\n",
    "| groups      | groups      |\n",
    "* torch没有pad_mode参数。\n",
    "* padding参数的取值和定义也不同。torch的padding参数融合了ms的pad_mode和padding两个参数的功能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff63bc-9e39-4849-85b1-a34b7e49aee4",
   "metadata": {},
   "source": [
    "2、返回值比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518c829d-80a5-4d98-b90c-09635ae35665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output:\n",
      " [[[[[-0.20217557 -0.20109153]\n",
      "    [-0.19783932 -0.19675523]\n",
      "    [-0.09659623 -0.09551224]]]]]\n",
      "torch     output:\n",
      " tensor([[[[[-0.2022, -0.2011],\n",
      "           [-0.1978, -0.1968],\n",
      "           [-0.0966, -0.0955]]]]])\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "import torch\n",
    "\n",
    "input = [[[[[-1.1790583,  -1.1461331,  -1.1132078 ],\n",
    "           [-1.0473574,  -1.0144321,  -0.98150694],\n",
    "           [-0.9156563,  -0.8827312,  -0.84980613],\n",
    "           [-1.0473574,  -1.0144321,  -0.98150694]]]]]\n",
    "weight = [[[[[ 0.07491168,  0.32591826],\n",
    "            [-0.30162174, -0.06628297]]]]]\n",
    "bias = [-0.12345]\n",
    "\n",
    "y1 = ms.ops.conv3d(ms.tensor(input), ms.tensor(weight), ms.tensor(bias))\n",
    "y2 = torch.nn.functional.conv3d(torch.tensor(input), torch.tensor(weight), torch.tensor(bias))\n",
    "print ('mindspore output:\\n',y1)\n",
    "print ('torch     output:\\n',y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675f5ea-72dd-44e9-ae9b-9b6fccd1b8ef",
   "metadata": {},
   "source": [
    "ms不返回类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ace53-ea30-4d5f-8351-6c344541c765",
   "metadata": {},
   "source": [
    "对齐pad_mode和padding参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6f0bad-1aa9-4282-85d6-4a30b7fe0b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output:\n",
      " [[[[[-0.20217557 -0.20109153  0.08920156]\n",
      "    [-0.19783932 -0.19675523  0.05934366]\n",
      "    [-0.09659623 -0.09551224  0.10893343]\n",
      "    [-0.5325312  -0.51933384 -0.19697633]]]]]\n",
      "torch     output:\n",
      " tensor([[[[[-0.2022, -0.2011,  0.0892],\n",
      "           [-0.1978, -0.1968,  0.0593],\n",
      "           [-0.0966, -0.0955,  0.1089],\n",
      "           [-0.5325, -0.5193, -0.1970]]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wy/5yzfdb6x7pvfxh89zcmf_w780000gn/T/ipykernel_77261/2744684280.py:2: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_68u_j54pu8/croot/pytorch-select_1717607460029/work/aten/src/ATen/native/Convolution.cpp:1032.)\n",
      "  y2 = torch.nn.functional.conv3d(torch.tensor(input), torch.tensor(weight), torch.tensor(bias),padding=\"same\")\n"
     ]
    }
   ],
   "source": [
    "y1 = ms.ops.conv3d(ms.tensor(input), ms.tensor(weight), ms.tensor(bias), pad_mode=\"same\", padding=0)\n",
    "y2 = torch.nn.functional.conv3d(torch.tensor(input), torch.tensor(weight), torch.tensor(bias),padding=\"same\")\n",
    "print ('mindspore output:\\n',y1)\n",
    "print ('torch     output:\\n',y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98581761-7abd-4109-9e86-a64291cfe20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output:\n",
      " [[[[[-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]]\n",
      "\n",
      "   [[-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]]\n",
      "\n",
      "   [[-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.04529852  0.3081487   0.29603538  0.21231768\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.43830466 -0.20217557 -0.20109153  0.08920156\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.4041105  -0.19783932 -0.19675523  0.05934366\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.35245714 -0.09659623 -0.09551224  0.10893343\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.46480292 -0.5325312  -0.51933384 -0.19697633\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]]\n",
      "\n",
      "   [[-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]]\n",
      "\n",
      "   [[-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]\n",
      "    [-0.12345    -0.12345    -0.12345    -0.12345    -0.12345\n",
      "     -0.12345   ]]]]]\n",
      "torch     output:\n",
      " tensor([[[[[-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235]],\n",
      "\n",
      "          [[-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235]],\n",
      "\n",
      "          [[-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.0453,  0.3081,  0.2960,  0.2123, -0.1235],\n",
      "           [-0.1235, -0.4383, -0.2022, -0.2011,  0.0892, -0.1235],\n",
      "           [-0.1235, -0.4041, -0.1978, -0.1968,  0.0593, -0.1235],\n",
      "           [-0.1235, -0.3525, -0.0966, -0.0955,  0.1089, -0.1235],\n",
      "           [-0.1235, -0.4648, -0.5325, -0.5193, -0.1970, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235]],\n",
      "\n",
      "          [[-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235]],\n",
      "\n",
      "          [[-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235],\n",
      "           [-0.1235, -0.1235, -0.1235, -0.1235, -0.1235, -0.1235]]]]])\n"
     ]
    }
   ],
   "source": [
    "y1 = ms.ops.conv3d(ms.tensor(input), ms.tensor(weight), ms.tensor(bias), pad_mode=\"pad\", padding=2)\n",
    "y2 = torch.nn.functional.conv3d(torch.tensor(input), torch.tensor(weight), torch.tensor(bias),padding=2)\n",
    "print ('mindspore output:\\n',y1)\n",
    "print ('torch     output:\\n',y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829c8db-4817-4d8d-b144-c5eb855935a5",
   "metadata": {},
   "source": [
    "3、当输入类型不正确时，报错比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fcbe1fa-7af2-4f85-9c27-c318cb2e7017",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:6861\u001b[0m, in \u001b[0;36mconv3d\u001b[0;34m(input, weight, bias, stride, pad_mode, padding, dilation, groups)\u001b[0m\n\u001b[1;32m   6706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconv3d\u001b[39m(\u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   6707\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6708\u001b[0m \u001b[38;5;124;03m    Applies a 3D convolution over an input tensor. The input tensor is typically of\u001b[39;00m\n\u001b[1;32m   6709\u001b[0m \u001b[38;5;124;03m    shape :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})`, where :math:`N` is batch size, :math:`C`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6859\u001b[0m \u001b[38;5;124;03m        (16, 32, 11, 32, 32)\u001b[39;00m\n\u001b[1;32m   6860\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6861\u001b[0m     weight_shape \u001b[38;5;241m=\u001b[39m \u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m   6862\u001b[0m     out_channel \u001b[38;5;241m=\u001b[39m weight_shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   6863\u001b[0m     kernel_size \u001b[38;5;241m=\u001b[39m weight_shape[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "y1 = ms.ops.conv3d(input, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1050b2d7-b6e4-4cce-90ed-9797c0dba5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv3d() received an invalid combination of arguments - got (list, list, list), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv3d() received an invalid combination of arguments - got (list, list, list), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n"
     ]
    }
   ],
   "source": [
    "y2 = torch.nn.functional.conv3d(input, weight, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59517714-1ef1-43d2-ac0e-7b84d4ab1c65",
   "metadata": {},
   "source": [
    "报错信息torch简洁明确。建议ms优化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
