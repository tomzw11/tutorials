{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620b1bb9-d188-4916-8a88-392b301e78dd",
   "metadata": {},
   "source": [
    "## mindspore.ops.conv1d(input, weight, bias=None, stride=1, pad_mode='valid', padding=0, dilation=1, groups=1) -〉 Tensor\n",
    "对输入Tensor计算一维卷积。\n",
    "\n",
    "- 输入：\n",
    "    * input：mindspore的tensor，输入。\n",
    "    * weight：mindspore的tensor，卷积核。\n",
    "    * bias：mindspore的tensor，偏置。\n",
    "    * stride：mindspore的tensor，步长。\n",
    "    * pad_mode：str，枚举值为\"same\"、\"valid\"或\"pad\"，填充模式。\n",
    "    * padding：int、tuple[int]、list[int]，填充的数量。\n",
    "    * dilation：int、tuple[int]，卷积核元素之间的间距。\n",
    "    * groups：int, 将input拆分为几组。\n",
    "\n",
    "- 返回：mindspore的tensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e9673-ea88-4efc-86bf-61455d0bcd74",
   "metadata": {},
   "source": [
    "1、参数比较：\n",
    "| mindspore   | torch       |\n",
    "| :----:      | :----:      |\n",
    "| input       | input       |\n",
    "| weight      | weight      |\n",
    "| bias        | bias        |\n",
    "| stride      | stride      |\n",
    "| pad_mode    | -           |\n",
    "| padding     | padding     |\n",
    "| dilation    | dilation    |\n",
    "| groups      | groups      |\n",
    "* torch没有pad_mode参数。\n",
    "* padding参数的取值和定义也不同。torch的padding参数融合了ms的pad_mode和padding两个参数的功能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff63bc-9e39-4849-85b1-a34b7e49aee4",
   "metadata": {},
   "source": [
    "2、返回值比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "518c829d-80a5-4d98-b90c-09635ae35665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output: [[[0.13251632 0.12148706]]]\n",
      "torch     output: tensor([[[0.1325, 0.1215]]])\n"
     ]
    }
   ],
   "source": [
    "input = [[[-1.1790583,  -1.1461331,  -1.1132078 ],\n",
    "           [-1.0473574,  -1.0144321,  -0.98150694],\n",
    "           [-0.9156563,  -0.8827312,  -0.84980613]]]\n",
    "weight = [[[ 0.07491168,  0.32591826],\n",
    "           [-0.30162174, -0.06628297],\n",
    "           [-0.30162174, -0.06628297]]]\n",
    "bias = [-0.12345]\n",
    "\n",
    "y1 = ms.ops.conv1d(ms.tensor(input), ms.tensor(weight), ms.tensor(bias))\n",
    "y2 = torch.nn.functional.conv1d(torch.tensor(input), torch.tensor(weight), torch.tensor(bias))\n",
    "print ('mindspore output:',y1)\n",
    "print ('torch     output:',y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675f5ea-72dd-44e9-ae9b-9b6fccd1b8ef",
   "metadata": {},
   "source": [
    "ms不返回类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daec08c6-ffb5-41e5-8d7a-278f19428fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output:\n",
      " [[[-0.20217557 -0.20109153]\n",
      "  [-0.47159967 -0.4705156 ]]]\n",
      "torch     output:\n",
      " tensor([[[-0.2022, -0.2011],\n",
      "         [-0.4716, -0.4705]]])\n"
     ]
    }
   ],
   "source": [
    "input = [[[-1.1790583,  -1.1461331,  -1.1132078 ],\n",
    "           [-1.0473574,  -1.0144321,  -0.98150694],\n",
    "           [-0.9156563,  -0.8827312,  -0.84980613],\n",
    "           [-0.9156563,  -0.8827312,  -0.84980613]]]\n",
    "weight = [[[ 0.07491168,  0.32591826],\n",
    "           [-0.30162174, -0.06628297]],\n",
    "          [[ 0.07491168,  0.32591826],\n",
    "           [-0.30162174, -0.06628297]]]\n",
    "bias = [-0.12345, -0.45]\n",
    "\n",
    "y1 = ms.ops.conv1d(ms.tensor(input), ms.tensor(weight), ms.tensor(bias), groups=2)\n",
    "y2 = torch.nn.functional.conv1d(torch.tensor(input), torch.tensor(weight), torch.tensor(bias), groups=2)\n",
    "print ('mindspore output:\\n',y1)\n",
    "print ('torch     output:\\n',y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a0f57-575b-4c96-9056-6c0bd454ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "对齐pad_mode和padding参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d6f0bad-1aa9-4282-85d6-4a30b7fe0b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output: [[[0.13251632 0.12148706 0.34552154]]]\n",
      "torch     output: tensor([[[0.1325, 0.1215, 0.3455]]])\n"
     ]
    }
   ],
   "source": [
    "input = [[[-1.1790583,  -1.1461331,  -1.1132078 ],\n",
    "           [-1.0473574,  -1.0144321,  -0.98150694],\n",
    "           [-0.9156563,  -0.8827312,  -0.84980613]]]\n",
    "weight = [[[ 0.07491168,  0.32591826],\n",
    "           [-0.30162174, -0.06628297],\n",
    "           [-0.30162174, -0.06628297]]]\n",
    "bias = [-0.12345]\n",
    "\n",
    "y1 = ms.ops.conv1d(ms.tensor(input), ms.tensor(weight), ms.tensor(bias), pad_mode=\"same\", padding=0)\n",
    "y2 = torch.nn.functional.conv1d(torch.tensor(input), torch.tensor(weight), torch.tensor(bias),padding=\"same\")\n",
    "print ('mindspore output:',y1)\n",
    "print ('torch     output:',y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98581761-7abd-4109-9e86-a64291cfe20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output:\n",
      " [[[-0.12345    -0.12345    -0.12345    -0.37761223  0.13251632\n",
      "    0.12148706  0.34552154 -0.12345    -0.12345    -0.12345   ]]]\n",
      "torch     output:\n",
      " tensor([[[-0.1235, -0.1235, -0.1235, -0.3776,  0.1325,  0.1215,  0.3455,\n",
      "          -0.1235, -0.1235, -0.1235]]])\n"
     ]
    }
   ],
   "source": [
    "y1 = ms.ops.conv1d(ms.tensor(input), ms.tensor(weight), ms.tensor(bias), pad_mode=\"pad\", padding=4)\n",
    "y2 = torch.nn.functional.conv1d(torch.tensor(input), torch.tensor(weight), torch.tensor(bias),padding=4)\n",
    "print ('mindspore output:\\n',y1)\n",
    "print ('torch     output:\\n',y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829c8db-4817-4d8d-b144-c5eb855935a5",
   "metadata": {},
   "source": [
    "3、当输入类型不正确时，报错比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fcbe1fa-7af2-4f85-9c27-c318cb2e7017",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:5616\u001b[0m, in \u001b[0;36mconv1d\u001b[0;34m(input, weight, bias, stride, pad_mode, padding, dilation, groups)\u001b[0m\n\u001b[1;32m   5504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconv1d\u001b[39m(\u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   5505\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5506\u001b[0m \u001b[38;5;124;03m    Applies a 1D convolution over an input tensor. The input Tensor is typically\u001b[39;00m\n\u001b[1;32m   5507\u001b[0m \u001b[38;5;124;03m    of shape :math:`(N, C_{in}, L_{in})`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5614\u001b[0m \u001b[38;5;124;03m        (4, 2, 5)\u001b[39;00m\n\u001b[1;32m   5615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5616\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m   5617\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, the input must be a 3D Tensor, but got input of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "y1 = ms.ops.conv1d(input, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1050b2d7-b6e4-4cce-90ed-9797c0dba5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv1d() received an invalid combination of arguments - got (list, list, list), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv1d() received an invalid combination of arguments - got (list, list, list), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n"
     ]
    }
   ],
   "source": [
    "y2 = torch.nn.functional.conv1d(input, weight, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59517714-1ef1-43d2-ac0e-7b84d4ab1c65",
   "metadata": {},
   "source": [
    "报错信息torch简洁明确。建议ms优化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
