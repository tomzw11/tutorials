{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620b1bb9-d188-4916-8a88-392b301e78dd",
   "metadata": {},
   "source": [
    "## mindspore.ops.logsumexp(input, axis, keep_dims=False) -〉 Tensor\n",
    "按指定维度对输入求对数指数和。\n",
    "\n",
    "- 输入:\n",
    "    * input必须为mindspore的tensor，数据类型为float16或float32。\n",
    "    * axis必须为int、tuple(int)或list(int)类型。\n",
    "    * keep_dims必须为bool型。\n",
    "- 返回：mindspore的tensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e925e-7e1d-4e81-810f-fd251bfcd7ac",
   "metadata": {},
   "source": [
    "1、参数比较：\n",
    "| mindspore   | torch       | \n",
    "| :----:      | :----:      | \n",
    "| input       | input       | \n",
    "| axis        | dim         |\n",
    "| keep_dims   | keepdim     |\n",
    "|             | out         |\n",
    "* torch提供了out出参方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff63bc-9e39-4849-85b1-a34b7e49aee4",
   "metadata": {},
   "source": [
    "2、返回值比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518c829d-80a5-4d98-b90c-09635ae35665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output:\n",
      " [[-0.41789412 -0.38496876 -0.35204363]\n",
      " [-0.22250915 -0.18958402 -0.15665895]]\n",
      "\n",
      "\n",
      "torch     output:\n",
      " tensor([[-0.4179, -0.3850, -0.3520],\n",
      "        [-0.2225, -0.1896, -0.1567]])\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "import torch\n",
    "\n",
    "input = [[[-1.1790583,  -1.1461331,  -1.1132078 ],\n",
    "          [-1.0473574,  -1.0144321,  -0.98150694]],\n",
    "\n",
    "         [[-0.9156563,  -0.8827312,  -0.84980613],\n",
    "          [-0.9156563,  -0.8827312,  -0.84980613]]]\n",
    "\n",
    "y1 = ms.ops.logsumexp(ms.tensor(input), 1)\n",
    "y2 = torch.logsumexp(torch.tensor(input), 1)\n",
    "print ('mindspore output:\\n',y1)\n",
    "print('\\n')\n",
    "print ('torch     output:\\n',y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068b3ce-1451-48ff-917b-c40263f0ebee",
   "metadata": {},
   "source": [
    "ms不返回类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f57fe-a2e6-4918-9e5f-ede7543cea00",
   "metadata": {},
   "source": [
    "3、报错信息比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcbe1fa-7af2-4f85-9c27-c318cb2e7017",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed calling ReduceMax with \"ReduceMax(keep_dims=bool)(x=List<List<List<float, float, float>, List<float, float, float>>, List<List<float, float, float>, List<float, float, float>>>, axis=int)\".\nThe valid calling should be: \n\"ReduceMax(keep_dims=<bool>)(x=<Tensor>, axis=<int, list of int, Tensor, tuple of int>)\".\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/pipeline/pynative/pynative_utils.cc:1294 PrintTypeCastError\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogsumexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6668\u001b[0m, in \u001b[0;36mlogsumexp\u001b[0;34m(input, axis, keep_dims)\u001b[0m\n\u001b[1;32m   6630\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6631\u001b[0m \u001b[38;5;124;03mReduces a dimension of a tensor by calculating exponential for all elements in the dimension,\u001b[39;00m\n\u001b[1;32m   6632\u001b[0m \u001b[38;5;124;03mthen calculate logarithm of the sum.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6664\u001b[0m \u001b[38;5;124;03m    (3, 1, 5, 6)\u001b[39;00m\n\u001b[1;32m   6665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6666\u001b[0m _reduce_sum \u001b[38;5;241m=\u001b[39m _get_cache_prim(P\u001b[38;5;241m.\u001b[39mReduceSum)(keep_dims)\n\u001b[0;32m-> 6668\u001b[0m input_max \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceMax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeep_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6669\u001b[0m input_exp \u001b[38;5;241m=\u001b[39m tensor_exp(\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m-\u001b[39m input_max)\n\u001b[1;32m   6670\u001b[0m input_sumexp \u001b[38;5;241m=\u001b[39m _reduce_sum(input_exp, axis)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/auto_generate/gen_ops_prim.py:11767\u001b[0m, in \u001b[0;36mReduceMax.__call__\u001b[0;34m(self, x, axis)\u001b[0m\n\u001b[1;32m  11766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, axis\u001b[38;5;241m=\u001b[39m()):\n\u001b[0;32m> 11767\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/primitive.py:405\u001b[0m, in \u001b[0;36mPrimitive.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_elim:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/primitive.py:1022\u001b[0m, in \u001b[0;36m_run_op\u001b[0;34m(obj, op_name, args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Single op execution function supported by ge in PyNative mode.\"\"\"\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _RunOpHook\u001b[38;5;241m.\u001b[39mcurrent:\n\u001b[0;32m-> 1022\u001b[0m     stub \u001b[38;5;241m=\u001b[39m \u001b[43m_pynative_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_op_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_stub(stub)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _RunOpHook\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhook(obj, args)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/common/api.py:1423\u001b[0m, in \u001b[0;36m_PyNativeExecutor.run_op_async\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_op_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;124;03m    Run single op async.\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;124;03m        StubNode, result of run op.\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_op_async\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed calling ReduceMax with \"ReduceMax(keep_dims=bool)(x=List<List<List<float, float, float>, List<float, float, float>>, List<List<float, float, float>, List<float, float, float>>>, axis=int)\".\nThe valid calling should be: \n\"ReduceMax(keep_dims=<bool>)(x=<Tensor>, axis=<int, list of int, Tensor, tuple of int>)\".\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/pipeline/pynative/pynative_utils.cc:1294 PrintTypeCastError\n"
     ]
    }
   ],
   "source": [
    "y1 = ms.ops.logsumexp(input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1050b2d7-b6e4-4cce-90ed-9797c0dba5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logsumexp() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogsumexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: logsumexp() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "y2 = torch.logsumexp(input, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59517714-1ef1-43d2-ac0e-7b84d4ab1c65",
   "metadata": {},
   "source": [
    "当输入类型不正确时，报错信息torch简洁明确。建议ms优化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
